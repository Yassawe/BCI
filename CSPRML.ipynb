{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GEOMSTATS_BACKEND=numpy\n",
      "env: NUMEXPR_MAX_THREADS=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "%env GEOMSTATS_BACKEND=numpy\n",
    "%env NUMEXPR_MAX_THREADS=12 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pickle\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.geometry.spd_matrices as spd\n",
    "from geomstats.learning.frechet_mean import FrechetMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename='BDproject/BCICompetition4_2a_SPD.pickle'\n",
    "#infile=open(filename,'rb')\n",
    "#SPDDataset=pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf0 = LogisticRegression(C=3, max_iter=1000)\n",
    "#clf1 = SVC(C=3, max_iter=1000)\n",
    "#clf2 = RidgeClassifier(alpha=3, max_iter=1000)\n",
    "#clf = [clf0, clf1, clf2]\n",
    "#clf_names = [\"Logistic Regression\", \"Support Vector Machine\", \"Ridge Classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, directory, conditions, epochs):\n",
    "        self.conditions=conditions\n",
    "        self.epochs=epochs\n",
    "        self.directory=directory\n",
    "    \n",
    "    def loadConcat(self, subject):\n",
    "        train_f=self.directory.format(subject, 'train')\n",
    "        test_f=self.directory.format(subject, 'test')\n",
    "\n",
    "        train = pickle.load(open(train_f, 'rb'))\n",
    "        tr_df=train.to_data_frame()\n",
    "\n",
    "        test = pickle.load(open(test_f, 'rb'))\n",
    "        ts_df=test.to_data_frame()  \n",
    "        ts_df['epoch']+=200\n",
    "\n",
    "        return pd.concat([tr_df, ts_df])\n",
    "\n",
    "    def convertToSPD(self, df, normalize=True):\n",
    "        SPD = [] \n",
    "        labels = [] \n",
    "        for i in range(self.epochs):\n",
    "            df_slice=df.loc[df['epoch']==i, :]\n",
    "            matrix=df_slice.iloc[:, 3:]\n",
    "            if normalize:\n",
    "                matrix=(matrix-matrix.mean())/matrix.std()\n",
    "                \n",
    "            label=df_slice['condition'].iloc[0]\n",
    "            for j in range(len(self.conditions)):\n",
    "                if label==self.conditions[j]:\n",
    "                    label=j #encoding of conditions to integers\n",
    "                    break        \n",
    "            covmat=matrix.cov().to_numpy()\n",
    "            SPD.append(covmat)\n",
    "            labels.append(label)\n",
    "            \n",
    "        return [SPD, labels]\n",
    "    \n",
    "    def generateSPDDataset(self, r, normalize=True):\n",
    "        SPDDataset=[]\n",
    "        for i in range(r[0]+1,r[1]+1):\n",
    "            df=self.loadConcat(i)\n",
    "            SPD = self.convertToSPD(df, normalize)\n",
    "            SPDDataset.append(SPD)\n",
    "        return SPDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = 20\n",
    "epochs = 400\n",
    "points = 512\n",
    "channels = 62\n",
    "directory = 'datasets/54subjects/Subject{}_{}.pickle'\n",
    "\n",
    "conditions=['left','right']\n",
    "\n",
    "# Throughout this code, left condition is marked 0, right condition is marked 1\n",
    "# Same applies for some arrays, 0th position is smh corresponding to left, 1th position is smh corresponding to right \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=DataPreparation(directory, conditions, epochs)\n",
    "SPDDataset = dp.generateSPDDataset([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomputeMeans(SPDDataset, subjects):\n",
    "    \n",
    "    def separate_classes(d, l):\n",
    "        classSpecificSPD=[]\n",
    "        for i in range(2): #two classes\n",
    "            indecies = [j for j,val in enumerate(l) if val==i]\n",
    "            classSPD = [d[j] for j in indecies]\n",
    "            classSpecificSPD.append(classSPD)\n",
    "        return classSpecificSPD\n",
    "    \n",
    "    channels = SPDDataset[0][0][0].shape[0]\n",
    "    \n",
    "    EM_mean_estimator = FrechetMean(spd.SPDMetricLogEuclidean(n=channels), max_iter=64)\n",
    "    AIRM_mean_estimator = FrechetMean(spd.SPDMetricAffine(n=channels), max_iter=64)\n",
    "    \n",
    "    LEM_means = []\n",
    "    AIRM_means = []\n",
    "    \n",
    "    for i in range(subjects):\n",
    "        d,l = SPDDataset[i]\n",
    "        classSpecificSPD = separate_classes(d,l)\n",
    "        \n",
    "        LEM_SPDk = []\n",
    "        AIRM_SPDk = []\n",
    "        \n",
    "        for SPD in classSpecificSPD:\n",
    "            LEM_mean_estimator.fit(SPD)\n",
    "            LEM_SPDk.append(LEM_mean_estimator.estimate_)\n",
    "            \n",
    "            AIRM_mean_estimator.fit(SPD)\n",
    "            AIRM_SPDk.append(AIRM_mean_estimator.estimate_)\n",
    "        \n",
    "        LEM_means.append(LEM_SPDk)\n",
    "        AIRM_means.append(AIRM_SPDk)\n",
    "    return LEM_means, AIRM_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n",
      "WARNING: Maximum number of iterations 64 reached. The mean may be inaccurate\n"
     ]
    }
   ],
   "source": [
    "LEM_means, AIRM_means = getMeans(SPDDataset, subjects, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump='BDproject/LEM_means.pickle'\n",
    "outfile = open(dump,'w+b')\n",
    "pickle.dump(LEM_means, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump='BDproject/AIRM_means.pickle'\n",
    "outfile = open(dump,'w+b')\n",
    "pickle.dump(AIRM_means, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
