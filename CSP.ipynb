{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GEOMSTATS_BACKEND=numpy\n",
    "%env NUMEXPR_MAX_THREADS=12 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import pickle\n",
    "\n",
    "\n",
    "import geomstats as gs\n",
    "import geomstats.geometry.spd_matrices as spd\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiemannCSP:\n",
    "    def __init__(self, channels=62):\n",
    "        self.channels=channels\n",
    "        \n",
    "    def separate_classes(self, d, l):\n",
    "        classSpecificSPD=[]\n",
    "        for i in range(2): #two classes\n",
    "            indecies = [j for j,val in enumerate(l) if val==i]\n",
    "            classSPD = [d[j] for j in indecies]\n",
    "            classSpecificSPD.append(classSPD)\n",
    "        return classSpecificSPD\n",
    "    \n",
    "    def estimateMeans(self, classSpecificSPD, metric):\n",
    "        if metric==\"AIRM\":\n",
    "            estimator = FrechetMean(spd.SPDMetricAffine(n=self.channels), max_iter=64)\n",
    "        elif metric==\"LEM\":\n",
    "            estimator = FrechetMean(spd.SPDMetricLogEuclidean(n=self.channels), max_iter=64)\n",
    "        else:\n",
    "            raise Exception(\"Not implemented metric\")\n",
    "            \n",
    "        means = []\n",
    "        \n",
    "        for SPD in classSpecificSPD:\n",
    "            estimator.fit(SPD)\n",
    "            mean = estimator.estimate_\n",
    "            means.append(mean)\n",
    "        return means\n",
    "        \n",
    "    \n",
    "    def getSpatialFilter(self, d, l, n, metric):\n",
    "        classSpecificSPD = self.separate_classes(d, l)\n",
    "        \n",
    "        if metric == \"classic\":\n",
    "            left_avg = sum(classSpecificSPD[0])/len(classSpecificSPD[0])\n",
    "            right_avg = sum(classSpecificSPD[1])/len(classSpecificSPD[1])\n",
    "        else:\n",
    "            left_avg, right_avg = self.estimateMeans(classSpecificSPD, metric)\n",
    "        \n",
    "        _,V = la.eigh(left_avg, left_avg+right_avg)\n",
    "    \n",
    "        V = np.concatenate((V[:, :n], V[:, -n:]), axis=1)\n",
    "        \n",
    "        return V\n",
    "    \n",
    "    def applySpatialFilter(self, dk, V):\n",
    "        a = np.dot(np.dot(V.T, dk), V)\n",
    "        f = np.log(np.diagonal(a))\n",
    "        return f\n",
    "    \n",
    "    def extractFeatures(self, d_train, l_train, d_test, l_test, n, metric):   \n",
    "        V = self.getSpatialFilter(d_train, l_train, n, metric)\n",
    "        \n",
    "        f_train = []\n",
    "        f_test = []\n",
    "            \n",
    "        for i in range(len(d_train)):\n",
    "            f_train.append(self.applySpatialFilter(d_train[i], V))\n",
    "   \n",
    "        for i in range(len(d_test)):\n",
    "            f_test.append(self.applySpatialFilter(d_test[i], V))\n",
    "            \n",
    "        return [f_train, l_train, f_test, l_test]\n",
    "\n",
    "def crossvalidate(d, l, channels, n, metric, classifier, kfolds = 5):\n",
    "    assert len(d)==len(l)\n",
    "    \n",
    "    \n",
    "    RCSP = RiemannCSP(channels)\n",
    "    \n",
    "    segment = int(len(d)/kfolds)\n",
    "    \n",
    "    k_accuracies = []\n",
    "    \n",
    "    for i in range(kfolds):\n",
    "        d_test = d[i*segment:(i+1)*segment]\n",
    "        l_test = l[i*segment:(i+1)*segment]\n",
    "        d_train = d[:i*segment] + d[(i+1)*segment:]\n",
    "        l_train = l[:i*segment] + l[(i+1)*segment:]\n",
    "        \n",
    "        [X_train, Y_train, X_test, Y_test] = RCSP.extractFeatures(d_train, l_train, d_test, l_test, n, metric)\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)        \n",
    "        acc = classifier.score(X_test, Y_test)\n",
    "        \n",
    "        k_accuracies.append(acc)\n",
    "    \n",
    "    av = sum(k_accuracies)/len(k_accuracies)\n",
    "    \n",
    "    return av, k_accuracies\n",
    "    \n",
    "    \n",
    "def classification(SPDDataset, subjects, epochs, channels, n, metrics, classifier, verbose=False):\n",
    "    score = []\n",
    "    for metric in metrics:\n",
    "        if verbose:\n",
    "            print(\"Metric is \" + metric)\n",
    "        aver = [] \n",
    "        for i in range(subjects):\n",
    "            d = SPDDataset[0][i*epochs:(i+1)*epochs]\n",
    "            l = SPDDataset[1][i*epochs:(i+1)*epochs]\n",
    "\n",
    "            av, _ = crossvalidate(d, l, channels, n, metric, classifier)\n",
    "            aver.append(av)\n",
    "            if verbose:\n",
    "                print(\"Subject \"+str(i+1)+\". Accuracy = \"+str(av))\n",
    "\n",
    "        a = sum(aver)/len(aver)\n",
    "        if verbose:\n",
    "            print(\"Average is = \"+str(a)+\"\\n\")\n",
    "        score.append(a)\n",
    "    return sum(score)/len(score)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='datasets/SPDDataset54.pickle'\n",
    "infile=open(filename,'rb')\n",
    "SPDDataset=pickle.load(infile)\n",
    "\n",
    "subjects = 10\n",
    "channels = 62\n",
    "epochs = 400\n",
    "\n",
    "# Throughout this code, left condition is marked 0, right condition is marked 1\n",
    "# Same applies for some arrays, 0th position is smh corresponding to left, 1th position is smh corresponding to right \n",
    "\n",
    "\n",
    "metrics = [\"AIRM\", \"LEM\"]\n",
    "\n",
    "n_range = [i for i in range(1,9)]\n",
    "c_range = [i/2 for i in range(1, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LDA: \")\n",
    "print(\"Peforming grid search for optimal hyperparameters\")\n",
    "\n",
    "best_acc = 0\n",
    "best_params = 0\n",
    "\n",
    "\n",
    "clf = LDA()\n",
    "for n in n_range:\n",
    "    average_acc = classification(SPDDataset, subjects, epochs, channels, n, metrics, clf) \n",
    "    if average_acc>best_acc:\n",
    "        best_acc = average_acc\n",
    "        best_params = n\n",
    "\n",
    "print(\"Best n is \" + str(best_params))\n",
    "\n",
    "clf = LDA()\n",
    "_ = classification(SPDDataset, subjects, epochs, channels, best_params, metrics, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
